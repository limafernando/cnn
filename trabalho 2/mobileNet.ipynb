{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.layers import Input, Conv2D, GlobalAveragePooling2D, Dense, BatchNormalization, Activation, DepthwiseConv2D\n",
    "from keras.models import Model\n",
    "from keras.models import Sequential\n",
    "from keras import optimizers as optimizers\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "from cv2 import imread, resize\n",
    "from os import listdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['n01443537',\n",
       " 'n01629819',\n",
       " 'n01641577',\n",
       " 'n01644900',\n",
       " 'n01698640',\n",
       " 'n01742172',\n",
       " 'n01768244',\n",
       " 'n01770393',\n",
       " 'n01774384',\n",
       " 'n01774750',\n",
       " 'n01784675',\n",
       " 'n01855672',\n",
       " 'n01882714',\n",
       " 'n01910747',\n",
       " 'n01917289',\n",
       " 'n01944390',\n",
       " 'n01945685',\n",
       " 'n01950731',\n",
       " 'n01983481',\n",
       " 'n01984695',\n",
       " 'n02002724',\n",
       " 'n02056570',\n",
       " 'n02058221',\n",
       " 'n02074367',\n",
       " 'n02085620',\n",
       " 'n02094433',\n",
       " 'n02099601',\n",
       " 'n02099712',\n",
       " 'n02106662',\n",
       " 'n02113799',\n",
       " 'n02123045',\n",
       " 'n02123394',\n",
       " 'n02124075',\n",
       " 'n02125311',\n",
       " 'n02129165',\n",
       " 'n02132136',\n",
       " 'n02165456',\n",
       " 'n02190166',\n",
       " 'n02206856',\n",
       " 'n02226429',\n",
       " 'n02231487',\n",
       " 'n02233338',\n",
       " 'n02236044',\n",
       " 'n02268443',\n",
       " 'n02279972',\n",
       " 'n02281406',\n",
       " 'n02321529',\n",
       " 'n02364673',\n",
       " 'n02395406',\n",
       " 'n02403003',\n",
       " 'n02410509',\n",
       " 'n02415577',\n",
       " 'n02423022',\n",
       " 'n02437312',\n",
       " 'n02480495',\n",
       " 'n02481823',\n",
       " 'n02486410',\n",
       " 'n02504458',\n",
       " 'n02509815',\n",
       " 'n02666196',\n",
       " 'n02669723',\n",
       " 'n02699494',\n",
       " 'n02730930',\n",
       " 'n02769748',\n",
       " 'n02788148',\n",
       " 'n02791270',\n",
       " 'n02793495',\n",
       " 'n02795169',\n",
       " 'n02802426',\n",
       " 'n02808440',\n",
       " 'n02814533',\n",
       " 'n02814860',\n",
       " 'n02815834',\n",
       " 'n02823428',\n",
       " 'n02837789',\n",
       " 'n02841315',\n",
       " 'n02843684',\n",
       " 'n02883205',\n",
       " 'n02892201',\n",
       " 'n02906734',\n",
       " 'n02909870',\n",
       " 'n02917067',\n",
       " 'n02927161',\n",
       " 'n02948072',\n",
       " 'n02950826',\n",
       " 'n02963159',\n",
       " 'n02977058',\n",
       " 'n02988304',\n",
       " 'n02999410',\n",
       " 'n03014705',\n",
       " 'n03026506',\n",
       " 'n03042490',\n",
       " 'n03085013',\n",
       " 'n03089624',\n",
       " 'n03100240',\n",
       " 'n03126707',\n",
       " 'n03160309',\n",
       " 'n03179701',\n",
       " 'n03201208',\n",
       " 'n03250847',\n",
       " 'n03255030',\n",
       " 'n03355925',\n",
       " 'n03388043',\n",
       " 'n03393912',\n",
       " 'n03400231',\n",
       " 'n03404251',\n",
       " 'n03424325',\n",
       " 'n03444034',\n",
       " 'n03447447',\n",
       " 'n03544143',\n",
       " 'n03584254',\n",
       " 'n03599486',\n",
       " 'n03617480',\n",
       " 'n03637318',\n",
       " 'n03649909',\n",
       " 'n03662601',\n",
       " 'n03670208',\n",
       " 'n03706229',\n",
       " 'n03733131',\n",
       " 'n03763968',\n",
       " 'n03770439',\n",
       " 'n03796401',\n",
       " 'n03804744',\n",
       " 'n03814639',\n",
       " 'n03837869',\n",
       " 'n03838899',\n",
       " 'n03854065',\n",
       " 'n03891332',\n",
       " 'n03902125',\n",
       " 'n03930313',\n",
       " 'n03937543',\n",
       " 'n03970156',\n",
       " 'n03976657',\n",
       " 'n03977966',\n",
       " 'n03980874',\n",
       " 'n03983396',\n",
       " 'n03992509',\n",
       " 'n04008634',\n",
       " 'n04023962',\n",
       " 'n04067472',\n",
       " 'n04070727',\n",
       " 'n04074963',\n",
       " 'n04099969',\n",
       " 'n04118538',\n",
       " 'n04133789',\n",
       " 'n04146614',\n",
       " 'n04149813',\n",
       " 'n04179913',\n",
       " 'n04251144',\n",
       " 'n04254777',\n",
       " 'n04259630',\n",
       " 'n04265275',\n",
       " 'n04275548',\n",
       " 'n04285008',\n",
       " 'n04311004',\n",
       " 'n04328186',\n",
       " 'n04356056',\n",
       " 'n04366367',\n",
       " 'n04371430',\n",
       " 'n04376876',\n",
       " 'n04398044',\n",
       " 'n04399382',\n",
       " 'n04417672',\n",
       " 'n04456115',\n",
       " 'n04465501',\n",
       " 'n04486054',\n",
       " 'n04487081',\n",
       " 'n04501370',\n",
       " 'n04507155',\n",
       " 'n04532106',\n",
       " 'n04532670',\n",
       " 'n04540053',\n",
       " 'n04560804',\n",
       " 'n04562935',\n",
       " 'n04596742',\n",
       " 'n04597913',\n",
       " 'n06596364',\n",
       " 'n07579787',\n",
       " 'n07583066',\n",
       " 'n07614500',\n",
       " 'n07615774',\n",
       " 'n07695742',\n",
       " 'n07711569',\n",
       " 'n07715103',\n",
       " 'n07720875',\n",
       " 'n07734744',\n",
       " 'n07747607',\n",
       " 'n07749582',\n",
       " 'n07753592',\n",
       " 'n07768694',\n",
       " 'n07871810',\n",
       " 'n07873807',\n",
       " 'n07875152',\n",
       " 'n07920052',\n",
       " 'n09193705',\n",
       " 'n09246464',\n",
       " 'n09256479',\n",
       " 'n09332890',\n",
       " 'n09428293',\n",
       " 'n12267677']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = 'new_dataset'\n",
    "\n",
    "listAux = listdir(path)\n",
    "\n",
    "pathTrain = path+'/'+'train'\n",
    "pathVal = path+'/'+'val'\n",
    "pathTest = path+'/'+'test'\n",
    "\n",
    "classes = listdir(pathTrain)\n",
    "classes.sort() #garante sempre a mesma ordem\n",
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder #de string para número\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "labelEncoder = LabelEncoder()\n",
    "classesCat = labelEncoder.fit_transform(classes) #encoder de string para número\n",
    "\n",
    "classesCat = to_categorical(classesCat) #one-hot\n",
    "\n",
    "dicClasses = {}\n",
    "\n",
    "for indice in range(len(classes)):\n",
    "    dicClasses[classes[indice]] = classesCat[indice]\n",
    "    \n",
    "#dicClasses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imagens de treino\n",
    "\n",
    "xTreino = []\n",
    "yTreino = []\n",
    "pathClasse = ''\n",
    "\n",
    "for classe in classes:\n",
    "    #print(pathClasse)\n",
    "    pathClasse = pathTrain + '/' + classe\n",
    "    imgsClasse = listdir(pathClasse)\n",
    "    \n",
    "    classeValue = dicClasses[classe]\n",
    "    \n",
    "    for img in imgsClasse:\n",
    "        \n",
    "        i = imread(pathClasse+'/'+img, 1)\n",
    "       \n",
    "        xTreino.append(i)\n",
    "        yTreino.append(classeValue)\n",
    "        \n",
    "                \n",
    "xTreino = np.array(xTreino)\n",
    "yTreino = np.array(yTreino)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 64, 3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xTreino[9000].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fazer o reshape aqui, aproveitando memória pra não estourar\n",
    "\n",
    "#rigthDim = (224,224)\n",
    "\n",
    "#for indice in range(len(xTreino)):\n",
    "#    xTreino[indice] =  resize(xTreino[indice], rigthDim)\n",
    "\n",
    "#não fiz o resize pq comeu muita memória, tentarei dps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#xTreino[23436].shape #conseguiu fazer reshape só em 23435 imagens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imagens de validação\n",
    "\n",
    "xVal = []\n",
    "yVal = []\n",
    "pathClasse = ''\n",
    "\n",
    "for classe in classes:\n",
    "    #print(pathClasse)\n",
    "    pathClasse = pathVal + '/' + classe\n",
    "    imgsClasse = listdir(pathClasse)\n",
    "    \n",
    "    classeValue = dicClasses[classe]\n",
    "    \n",
    "    for img in imgsClasse:\n",
    "        \n",
    "        i = imread(pathClasse+'/'+img, 1)\n",
    "       \n",
    "        xVal.append(i)\n",
    "        yVal.append(classeValue)\n",
    "        \n",
    "                \n",
    "xVal = np.array(xVal)\n",
    "yVal = np.array(yVal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(64, 64, 3)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(xVal))\n",
    "xVal[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imagens de teste\n",
    "\n",
    "xTeste = []\n",
    "yTeste = []\n",
    "pathClasse = ''\n",
    "\n",
    "for classe in classes:\n",
    "    #print(pathClasse)\n",
    "    pathClasse = pathTest + '/' + classe\n",
    "    imgsClasse = listdir(pathClasse)\n",
    "    \n",
    "    classeValue = dicClasses[classe]\n",
    "    \n",
    "    for img in imgsClasse:\n",
    "        \n",
    "        i = imread(pathClasse+'/'+img, 1)\n",
    "       \n",
    "        xTeste.append(i)\n",
    "        yTeste.append(classeValue)\n",
    "        \n",
    "                \n",
    "xTeste = np.array(xTeste)\n",
    "yTeste = np.array(yTeste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(64, 64, 3)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(xTeste))\n",
    "xTeste[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(yTreino[0]))\n",
    "yTreino[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parâmetros\n",
    "batch_size = 32\n",
    "learning_rate = 5e-4\n",
    "decay = 0.0\n",
    "momentum = 0.9\n",
    "num_classes = 200\n",
    "epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#para checar a estrutura da rede\n",
    "\n",
    "#from keras.applications import MobileNet\n",
    "\n",
    "#model = MobileNet()\n",
    "#model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mobileNet():\n",
    "    \n",
    "    model = Sequential()\n",
    "\n",
    "    dim = (64,64,3)\n",
    "    #dim = (224,224,3)\n",
    "    \n",
    "    model.add(Conv2D(filters=32, kernel_size=(3, 3), strides=(1, 1), padding='same', kernel_initializer='he_normal', activation='relu', use_bias=False, input_shape=dim))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(DepthwiseConv2D(kernel_size=(3, 3), strides=(1, 1), padding='same', kernel_initializer='he_normal', activation='relu', use_bias=False))\n",
    "    model.add(BatchNormalization())\n",
    "   \n",
    "    \n",
    "    model.add(Conv2D(filters=64, kernel_size=(1, 1), strides=(1, 1), padding='same', kernel_initializer='he_normal', activation='relu', use_bias=False))\n",
    "    model.add(BatchNormalization())\n",
    "   \n",
    "\n",
    "    model.add(DepthwiseConv2D(kernel_size=(3, 3), strides=(2, 2), padding='same', kernel_initializer='he_normal', activation='relu', use_bias=False))\n",
    "    model.add(BatchNormalization())\n",
    "   \n",
    "    \n",
    "    model.add(Conv2D(filters=128, kernel_size=(1, 1), strides=(1, 1), padding='same', kernel_initializer='he_normal', activation='relu', use_bias=False))\n",
    "    model.add(BatchNormalization())\n",
    "   \n",
    "\n",
    "    model.add(DepthwiseConv2D(kernel_size=(3, 3), strides=(1, 1), padding='same', kernel_initializer='he_normal', activation='relu', use_bias=False))\n",
    "    model.add(BatchNormalization())\n",
    "   \n",
    "    \n",
    "    model.add(Conv2D(filters=128, kernel_size=(1, 1), strides=(1, 1), padding='same', kernel_initializer='he_normal', activation='relu', use_bias=False))\n",
    "    model.add(BatchNormalization())\n",
    "   \n",
    "\n",
    "    model.add(DepthwiseConv2D(kernel_size=(3, 3), strides=(1, 1), padding='same', kernel_initializer='he_normal', activation='relu', use_bias=False))\n",
    "    model.add(BatchNormalization())\n",
    "   \n",
    "    \n",
    "    model.add(Conv2D(filters=256, kernel_size=(1, 1), strides=(1, 1), padding='same', kernel_initializer='he_normal', activation='relu', use_bias=False))\n",
    "    model.add(BatchNormalization())\n",
    "   \n",
    "\n",
    "    model.add(DepthwiseConv2D(kernel_size=(3, 3), strides=(1, 1), padding='same', kernel_initializer='he_normal', activation='relu', use_bias=False))\n",
    "    model.add(BatchNormalization())\n",
    "   \n",
    "    \n",
    "    model.add(Conv2D(filters=256, kernel_size=(1, 1), strides=(1, 1), padding='same', kernel_initializer='he_normal', activation='relu', use_bias=False))\n",
    "    model.add(BatchNormalization())\n",
    "   \n",
    "\n",
    "    model.add(DepthwiseConv2D(kernel_size=(3, 3), strides=(2, 2), padding='same', kernel_initializer='he_normal', activation='relu', use_bias=False))\n",
    "    model.add(BatchNormalization())\n",
    "   \n",
    "    \n",
    "    model.add(Conv2D(filters=256, kernel_size=(1, 1), strides=(1, 1), padding='same', kernel_initializer='he_normal', activation='relu', use_bias=False))\n",
    "    model.add(BatchNormalization())\n",
    "   \n",
    "\n",
    "    for _ in range(5):\n",
    "        model.add(DepthwiseConv2D(kernel_size=(3, 3), strides=(1, 1), padding='same', kernel_initializer='he_normal', activation='relu', use_bias=False))\n",
    "        model.add(BatchNormalization())\n",
    "       \n",
    "            \n",
    "        model.add(Conv2D(filters=256, kernel_size=(1, 1), strides=(1, 1), padding='same', kernel_initializer='he_normal', activation='relu', use_bias=False))\n",
    "        model.add(BatchNormalization())\n",
    "       \n",
    "\n",
    "    model.add(DepthwiseConv2D(kernel_size=(3, 3), strides=(2, 2), padding='same', kernel_initializer='he_normal', activation='relu', use_bias=False))\n",
    "    model.add(BatchNormalization())\n",
    "   \n",
    "    \n",
    "    model.add(Conv2D(filters=512, kernel_size=(1, 1), strides=(1, 1), padding='same', kernel_initializer='he_normal', activation='relu', use_bias=False))\n",
    "    model.add(BatchNormalization())\n",
    "   \n",
    "\n",
    "    model.add(DepthwiseConv2D(kernel_size=(3, 3), strides=(1, 1), padding='same', kernel_initializer='he_normal', activation='relu', use_bias=False))\n",
    "    model.add(BatchNormalization())\n",
    "   \n",
    "    \n",
    "    model.add(Conv2D(filters=512, kernel_size=(1, 1), strides=(1, 1), padding='same', kernel_initializer='he_normal', activation='relu', use_bias=False))\n",
    "    model.add(BatchNormalization())\n",
    "   \n",
    "\n",
    "    model.add(GlobalAveragePooling2D())\n",
    "    model.add(Dense(num_classes, kernel_initializer='he_normal', activation='softmax'))\n",
    "    \n",
    "    adam = optimizers.Adam(lr=learning_rate, decay=decay)\n",
    "    #sgd = optimizers.SGD(lr=0.1, decay=0.01)\n",
    "    \n",
    "    model.compile(optimizer = adam, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_43 (Conv2D)           (None, 64, 64, 32)        864       \n",
      "_________________________________________________________________\n",
      "batch_normalization_82 (Batc (None, 64, 64, 32)        128       \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_40 (Depthwi (None, 64, 64, 32)        288       \n",
      "_________________________________________________________________\n",
      "batch_normalization_83 (Batc (None, 64, 64, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_44 (Conv2D)           (None, 64, 64, 64)        2048      \n",
      "_________________________________________________________________\n",
      "batch_normalization_84 (Batc (None, 64, 64, 64)        256       \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_41 (Depthwi (None, 32, 32, 64)        576       \n",
      "_________________________________________________________________\n",
      "batch_normalization_85 (Batc (None, 32, 32, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_45 (Conv2D)           (None, 32, 32, 128)       8192      \n",
      "_________________________________________________________________\n",
      "batch_normalization_86 (Batc (None, 32, 32, 128)       512       \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_42 (Depthwi (None, 32, 32, 128)       1152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_87 (Batc (None, 32, 32, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv2d_46 (Conv2D)           (None, 32, 32, 128)       16384     \n",
      "_________________________________________________________________\n",
      "batch_normalization_88 (Batc (None, 32, 32, 128)       512       \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_43 (Depthwi (None, 32, 32, 128)       1152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_89 (Batc (None, 32, 32, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv2d_47 (Conv2D)           (None, 32, 32, 256)       32768     \n",
      "_________________________________________________________________\n",
      "batch_normalization_90 (Batc (None, 32, 32, 256)       1024      \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_44 (Depthwi (None, 32, 32, 256)       2304      \n",
      "_________________________________________________________________\n",
      "batch_normalization_91 (Batc (None, 32, 32, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv2d_48 (Conv2D)           (None, 32, 32, 256)       65536     \n",
      "_________________________________________________________________\n",
      "batch_normalization_92 (Batc (None, 32, 32, 256)       1024      \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_45 (Depthwi (None, 16, 16, 256)       2304      \n",
      "_________________________________________________________________\n",
      "batch_normalization_93 (Batc (None, 16, 16, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv2d_49 (Conv2D)           (None, 16, 16, 256)       65536     \n",
      "_________________________________________________________________\n",
      "batch_normalization_94 (Batc (None, 16, 16, 256)       1024      \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_46 (Depthwi (None, 16, 16, 256)       2304      \n",
      "_________________________________________________________________\n",
      "batch_normalization_95 (Batc (None, 16, 16, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv2d_50 (Conv2D)           (None, 16, 16, 256)       65536     \n",
      "_________________________________________________________________\n",
      "batch_normalization_96 (Batc (None, 16, 16, 256)       1024      \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_47 (Depthwi (None, 16, 16, 256)       2304      \n",
      "_________________________________________________________________\n",
      "batch_normalization_97 (Batc (None, 16, 16, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv2d_51 (Conv2D)           (None, 16, 16, 256)       65536     \n",
      "_________________________________________________________________\n",
      "batch_normalization_98 (Batc (None, 16, 16, 256)       1024      \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_48 (Depthwi (None, 16, 16, 256)       2304      \n",
      "_________________________________________________________________\n",
      "batch_normalization_99 (Batc (None, 16, 16, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv2d_52 (Conv2D)           (None, 16, 16, 256)       65536     \n",
      "_________________________________________________________________\n",
      "batch_normalization_100 (Bat (None, 16, 16, 256)       1024      \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_49 (Depthwi (None, 16, 16, 256)       2304      \n",
      "_________________________________________________________________\n",
      "batch_normalization_101 (Bat (None, 16, 16, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv2d_53 (Conv2D)           (None, 16, 16, 256)       65536     \n",
      "_________________________________________________________________\n",
      "batch_normalization_102 (Bat (None, 16, 16, 256)       1024      \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_50 (Depthwi (None, 16, 16, 256)       2304      \n",
      "_________________________________________________________________\n",
      "batch_normalization_103 (Bat (None, 16, 16, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv2d_54 (Conv2D)           (None, 16, 16, 256)       65536     \n",
      "_________________________________________________________________\n",
      "batch_normalization_104 (Bat (None, 16, 16, 256)       1024      \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_51 (Depthwi (None, 8, 8, 256)         2304      \n",
      "_________________________________________________________________\n",
      "batch_normalization_105 (Bat (None, 8, 8, 256)         1024      \n",
      "_________________________________________________________________\n",
      "conv2d_55 (Conv2D)           (None, 8, 8, 512)         131072    \n",
      "_________________________________________________________________\n",
      "batch_normalization_106 (Bat (None, 8, 8, 512)         2048      \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_52 (Depthwi (None, 8, 8, 512)         4608      \n",
      "_________________________________________________________________\n",
      "batch_normalization_107 (Bat (None, 8, 8, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv2d_56 (Conv2D)           (None, 8, 8, 512)         262144    \n",
      "_________________________________________________________________\n",
      "batch_normalization_108 (Bat (None, 8, 8, 512)         2048      \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_4 ( (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 200)               102600    \n",
      "=================================================================\n",
      "Total params: 1,066,376\n",
      "Trainable params: 1,053,704\n",
      "Non-trainable params: 12,672\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = mobileNet()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 90000 samples, validate on 10000 samples\n",
      "Epoch 0/20\n",
      " 1184/90000 [..............................] - ETA: 5:59:58 - loss: 5.3157 - acc: 0.0051"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-5c31aae20991>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxTreino\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myTreino\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxVal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myVal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1397\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1398\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1399\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1400\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1401\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = model.fit(xTreino, yTreino, validation_data=(xVal, yVal), epochs=epochs, batch_size=batch_size, initial_epoch=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training & validation accuracy values\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Val'], loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training & validation loss values\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Val'], loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.evaluate(xTeste, yTeste)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
