{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import keras\n",
    "\n",
    "from keras.datasets import mnist\n",
    "\n",
    "from keras.models import Sequential\n",
    "\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#carrega o banco de dados do mnist\n",
    "\n",
    "(xTrain, yTrain), (xTest, yTest) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#xTrain\n",
    "#len(xTrain)\n",
    "#xTrain.shape\n",
    "#yTrain\n",
    "#yTrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "[1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "#One-hot encoding\n",
    "yTeste = to_categorical(yTest)\n",
    "yTreino = to_categorical(yTrain)\n",
    "print(yTreino[0])\n",
    "print(yTreino[1])\n",
    "print(yTreino[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualizando exemplo de imagem\n",
    "\n",
    "data = xTrain[0]\n",
    "img = Image.fromarray(data, 'L') #'L' para imagem em escala de cinza (8-bit)\n",
    "\n",
    "#img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "w, h = 32,32\n",
    "img = img.resize((w,h), Image.ANTIALIAS)\n",
    "img\n",
    "\n",
    "a = np.asarray(img)\n",
    "\n",
    "img = Image.fromarray(a, 'L') #'L' para imagem em escala de cinza (8-bit)\n",
    "#img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ajuste das dimensões das imagens de treino\n",
    "\n",
    "w, h = 32, 32\n",
    "\n",
    "auxList = []\n",
    "\n",
    "for i in range(len(xTrain)):\n",
    "    \n",
    "    img = Image.fromarray(xTrain[i], 'L') #'L' para imagem em escala de cinza (8-bit)\n",
    "\n",
    "    img = img.resize((w,h), Image.ANTIALIAS)\n",
    "    \n",
    "    auxList.append(np.asarray(img))\n",
    "\n",
    "xTreino = np.array(auxList)        \n",
    "#xTreino.shape\n",
    "\n",
    "xTreino = xTreino.reshape((60000,32,32,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array_equal(xTreino[0], xTreino[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ajuste das dimensões das imagens de teste\n",
    "\n",
    "w, h = 32, 32\n",
    "\n",
    "auxList = []\n",
    "\n",
    "for i in range(len(xTest)):\n",
    "    \n",
    "    img = Image.fromarray(xTest[i], 'L') #'L' para imagem em escala de cinza (8-bit)\n",
    "\n",
    "    img = img.resize((w,h), Image.ANTIALIAS)\n",
    "\n",
    "    auxList.append(np.asarray(img))\n",
    "\n",
    "xTeste = np.array(auxList)\n",
    "#xTeste.shape\n",
    "\n",
    "xTeste = xTeste.reshape((10000, 32, 32, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"#visualizando exemplo de imagem\\n\\ndata = xTreino[0]\\nimg = Image.fromarray(data, 'L') #'L' para imagem em escala de cinza (8-bit)\\n\\n#print(data.shape)\\nimg\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''#visualizando exemplo de imagem\n",
    "\n",
    "data = xTreino[0]\n",
    "img = Image.fromarray(data, 'L') #'L' para imagem em escala de cinza (8-bit)\n",
    "\n",
    "#print(data.shape)\n",
    "img'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def leNet():\n",
    "    \n",
    "    classificador = Sequential()\n",
    "    \n",
    "    #imagem 32x32\n",
    "    #Camada convolucional 1\n",
    "    classificador.add(Conv2D(filters = 6, kernel_size = 5, strides = 1, activation = 'relu', kernel_initializer='random_uniform', input_shape = (32,32,1)))\n",
    "    \n",
    "    #imagem 28x28\n",
    "    #Camada de pooling 1\n",
    "    classificador.add(MaxPooling2D(pool_size = 2, strides = 2))\n",
    "    \n",
    "    #imagem 14x14\n",
    "    #Camada convolucional 2\n",
    "    classificador.add(Conv2D(filters = 16, kernel_size = 5, strides = 1, activation = 'relu', kernel_initializer='random_uniform', input_shape = (14,14,6)))\n",
    "    \n",
    "    #imagem 10x10\n",
    "    #Camada de pooling 2\n",
    "    classificador.add(MaxPooling2D(pool_size = 2, strides = 2))\n",
    "    \n",
    "    #imagem 5x5\n",
    "    #Flatten\n",
    "    classificador.add(Flatten())\n",
    "    \n",
    "    #Camada totalmente conectada 1\n",
    "    classificador.add(Dense(units = 120, activation = 'relu', kernel_initializer='random_uniform'))\n",
    "    \n",
    "    #Camada totalmente conectada 2\n",
    "    classificador.add(Dense(units = 84, activation = 'relu',  kernel_initializer='random_uniform',))\n",
    "    \n",
    "    #Camada de saída\n",
    "    classificador.add(Dense(units = 10, activation = 'softmax',  kernel_initializer='random_uniform',))\n",
    "    \n",
    "    classificador.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "    \n",
    "    return  classificador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50001 samples, validate on 9999 samples\n",
      "Epoch 0/50\n",
      "50001/50001 [==============================] - 53s 1ms/step - loss: 0.1425 - acc: 0.9549 - val_loss: 0.0682 - val_acc: 0.9805\n",
      "Epoch 1/50\n",
      "50001/50001 [==============================] - 53s 1ms/step - loss: 0.0579 - acc: 0.9826 - val_loss: 0.0528 - val_acc: 0.9849\n",
      "Epoch 2/50\n",
      "50001/50001 [==============================] - 61s 1ms/step - loss: 0.0465 - acc: 0.9856 - val_loss: 0.0572 - val_acc: 0.9829\n",
      "Epoch 3/50\n",
      "50001/50001 [==============================] - 62s 1ms/step - loss: 0.0398 - acc: 0.9883 - val_loss: 0.0501 - val_acc: 0.9869\n",
      "Epoch 4/50\n",
      "50001/50001 [==============================] - 59s 1ms/step - loss: 0.0334 - acc: 0.9905 - val_loss: 0.0599 - val_acc: 0.9836\n",
      "Epoch 5/50\n",
      "50001/50001 [==============================] - 57s 1ms/step - loss: 0.0320 - acc: 0.9905 - val_loss: 0.0525 - val_acc: 0.9872\n",
      "Epoch 6/50\n",
      "50001/50001 [==============================] - 54s 1ms/step - loss: 0.0268 - acc: 0.9920 - val_loss: 0.0580 - val_acc: 0.9851\n",
      "Epoch 7/50\n",
      "50001/50001 [==============================] - 53s 1ms/step - loss: 0.0229 - acc: 0.9934 - val_loss: 0.0831 - val_acc: 0.9837\n",
      "Epoch 8/50\n",
      "50001/50001 [==============================] - 53s 1ms/step - loss: 0.0285 - acc: 0.9922 - val_loss: 0.0529 - val_acc: 0.9877\n",
      "Epoch 9/50\n",
      "50001/50001 [==============================] - 51s 1ms/step - loss: 0.0226 - acc: 0.9940 - val_loss: 0.0672 - val_acc: 0.9846\n",
      "Epoch 10/50\n",
      "50001/50001 [==============================] - 52s 1ms/step - loss: 0.0226 - acc: 0.9940 - val_loss: 0.0711 - val_acc: 0.9841\n",
      "Epoch 11/50\n",
      "50001/50001 [==============================] - 53s 1ms/step - loss: 0.0217 - acc: 0.9945 - val_loss: 0.0720 - val_acc: 0.9875\n",
      "Epoch 12/50\n",
      "50001/50001 [==============================] - 52s 1ms/step - loss: 0.0242 - acc: 0.9941 - val_loss: 0.0659 - val_acc: 0.9874\n",
      "Epoch 13/50\n",
      "50001/50001 [==============================] - 53s 1ms/step - loss: 0.0206 - acc: 0.9953 - val_loss: 0.0644 - val_acc: 0.9885\n",
      "Epoch 14/50\n",
      "50001/50001 [==============================] - 52s 1ms/step - loss: 0.0197 - acc: 0.9947 - val_loss: 0.0736 - val_acc: 0.9859\n",
      "Epoch 15/50\n",
      "50001/50001 [==============================] - 54s 1ms/step - loss: 0.0188 - acc: 0.9950 - val_loss: 0.1236 - val_acc: 0.9821\n",
      "Epoch 16/50\n",
      "50001/50001 [==============================] - 54s 1ms/step - loss: 0.0193 - acc: 0.9951 - val_loss: 0.0910 - val_acc: 0.9860\n",
      "Epoch 17/50\n",
      "50001/50001 [==============================] - 53s 1ms/step - loss: 0.0210 - acc: 0.9950 - val_loss: 0.0822 - val_acc: 0.9870\n",
      "Epoch 18/50\n",
      "50001/50001 [==============================] - 53s 1ms/step - loss: 0.0182 - acc: 0.9954 - val_loss: 0.0832 - val_acc: 0.9862\n",
      "Epoch 19/50\n",
      "50001/50001 [==============================] - 54s 1ms/step - loss: 0.0197 - acc: 0.9952 - val_loss: 0.0879 - val_acc: 0.9860\n",
      "Epoch 20/50\n",
      "50001/50001 [==============================] - 55s 1ms/step - loss: 0.0168 - acc: 0.9960 - val_loss: 0.1061 - val_acc: 0.9851\n",
      "Epoch 21/50\n",
      "50001/50001 [==============================] - 55s 1ms/step - loss: 0.0266 - acc: 0.9944 - val_loss: 0.0806 - val_acc: 0.9876\n",
      "Epoch 22/50\n",
      "50001/50001 [==============================] - 52s 1ms/step - loss: 0.0155 - acc: 0.9969 - val_loss: 0.1085 - val_acc: 0.9852\n",
      "Epoch 23/50\n",
      "50001/50001 [==============================] - 52s 1ms/step - loss: 0.0227 - acc: 0.9955 - val_loss: 0.0876 - val_acc: 0.9877\n",
      "Epoch 24/50\n",
      "50001/50001 [==============================] - 53s 1ms/step - loss: 0.0153 - acc: 0.9966 - val_loss: 0.0836 - val_acc: 0.9885\n",
      "Epoch 25/50\n",
      "50001/50001 [==============================] - 52s 1ms/step - loss: 0.0221 - acc: 0.9956 - val_loss: 0.1001 - val_acc: 0.9865\n",
      "Epoch 26/50\n",
      "50001/50001 [==============================] - 52s 1ms/step - loss: 0.0147 - acc: 0.9967 - val_loss: 0.1109 - val_acc: 0.9875\n",
      "Epoch 27/50\n",
      "50001/50001 [==============================] - 51s 1ms/step - loss: 0.0198 - acc: 0.9958 - val_loss: 0.1216 - val_acc: 0.9868\n",
      "Epoch 28/50\n",
      "50001/50001 [==============================] - 51s 1ms/step - loss: 0.0221 - acc: 0.9961 - val_loss: 0.1018 - val_acc: 0.9885\n",
      "Epoch 29/50\n",
      "50001/50001 [==============================] - 50s 990us/step - loss: 0.0260 - acc: 0.9956 - val_loss: 0.1024 - val_acc: 0.9867\n",
      "Epoch 30/50\n",
      "50001/50001 [==============================] - 52s 1ms/step - loss: 0.0198 - acc: 0.9961 - val_loss: 0.0960 - val_acc: 0.9885\n",
      "Epoch 31/50\n",
      "50001/50001 [==============================] - 52s 1ms/step - loss: 0.0229 - acc: 0.9963 - val_loss: 0.1079 - val_acc: 0.9882\n",
      "Epoch 32/50\n",
      "50001/50001 [==============================] - 55s 1ms/step - loss: 0.0196 - acc: 0.9967 - val_loss: 0.1044 - val_acc: 0.9876\n",
      "Epoch 33/50\n",
      "50001/50001 [==============================] - 52s 1ms/step - loss: 0.0203 - acc: 0.9964 - val_loss: 0.0983 - val_acc: 0.9878\n",
      "Epoch 34/50\n",
      "50001/50001 [==============================] - 50s 998us/step - loss: 0.0144 - acc: 0.9973 - val_loss: 0.1193 - val_acc: 0.9857\n",
      "Epoch 35/50\n",
      "50001/50001 [==============================] - 48s 959us/step - loss: 0.0255 - acc: 0.9958 - val_loss: 0.0990 - val_acc: 0.9878\n",
      "Epoch 36/50\n",
      "50001/50001 [==============================] - 51s 1ms/step - loss: 0.0192 - acc: 0.9969 - val_loss: 0.1103 - val_acc: 0.9880\n",
      "Epoch 37/50\n",
      "50001/50001 [==============================] - 56s 1ms/step - loss: 0.0197 - acc: 0.9966 - val_loss: 0.0932 - val_acc: 0.9895\n",
      "Epoch 38/50\n",
      "16320/50001 [========>.....................] - ETA: 35s - loss: 0.0356 - acc: 0.9955"
     ]
    }
   ],
   "source": [
    "model = leNet()\n",
    "#print(xTreino.shape)\n",
    "history = model.fit(xTreino, yTreino, validation_split=0.16665, epochs=50, batch_size=32, initial_epoch=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training & validation accuracy values\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training & validation loss values\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(xTeste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cont = 0\n",
    "correto = 0\n",
    "incorreto = 0\n",
    "for ele in yTeste:\n",
    "    if np.array_equal(ele, pred[cont]):\n",
    "        correto += 1\n",
    "    else:\n",
    "        incorreto += 1\n",
    "    cont += 1\n",
    "    \n",
    "print(correto)\n",
    "print(incorreto)\n",
    "print(correto/(incorreto+correto))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
